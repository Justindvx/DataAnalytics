> cbcsubset=subset(CBC,select=c(M,R,F,FirstPurch,ChildBks,YouthBks,CookBks,DoItYBks,
+ RefBks,ArtBks,GeogBks,ItalCook,ItalAtlas,ItalArt))
Error in subset(CBC, select = c(M, R, F, FirstPurch, ChildBks, YouthBks,  : 
  error in evaluating the argument 'x' in selecting a method for function 'subset': Error: object 'CBC' not found
> cbcsubset=subset(cbc,select=c(M,R,F,FirstPurch,ChildBks,YouthBks,CookBks,DoItYBks,
+ RefBks,ArtBks,GeogBks,ItalCook,ItalAtlas,ItalArt))
> head(cbcsubset)
    M  R F FirstPurch ChildBks YouthBks CookBks DoItYBks RefBks ArtBks GeogBks ItalCook ItalAtlas ItalArt
1 297 14 2         22        0        1       1        0      0      0       0        0         0       0
2 128  8 2         10        0        0       0        0      0      0       0        0         0       0
3 138 22 7         56        2        1       2        0      1      0       1        1         0       0
4 228  2 1          2        0        0       0        0      0      0       0        0         0       0
5 257 10 1         10        0        0       0        0      0      0       0        0         0       0
6 145  6 2         12        0        0       0        0      0      0       0        0         0       0
> cbcsubset2=subset(cbc,select=c(Gender,Florence))
> cbcsubset=subset(cbc,select=c(M,R,F,FirstPurch,ChildBks,YouthBks,CookBks,DoItYBks,
+ RefBks,ArtBks,GeogBks,ItalCook,ItalAtlas,ItalArt,Related.Purchase))
> cbcsubset = discretize(cbcsubset, disc="equalfreq", nbins=4 )
> cbcMain=cbind(cbcsubset,cbcsubset2)
> head(cbcMain)
  M R F FirstPurch ChildBks YouthBks CookBks DoItYBks RefBks ArtBks GeogBks ItalCook ItalAtlas ItalArt Related.Purchase Gender Florence
1 4 3 2          3        1        4       3        1      1      1       1        1         1       1                1      1        0
2 1 1 2          1        1        1       1        1      1      1       1        1         1       1                1      0        0
3 2 4 4          4        4        4       4        1      4      1       3        4         1       1                4      1        0
4 3 1 1          1        1        1       1        1      1      1       1        1         1       1                1      1        0
5 3 2 1          1        1        1       1        1      1      1       1        1         1       1                1      1        0
6 2 1 2          1        1        1       1        1      1      1       1        1         1       1                1      1        0
> dim(cbcMain)
[1] 4000   17
> cbcMain$M=as.factor(M)
>  cbcMain$R=as.factor(R)
Error in is.factor(x) : object 'R' not found
>  cbcMain$F=as.factor(F)
>  cbcMain$FirstPurch=as.factor(FirstPurch)
Error in is.factor(x) : object 'FirstPurch' not found
>  cbcMain$ChildBks=as.factor(ChildBks)
>  cbcMain$YouthBks=as.factor(YouthBks)
>  cbcMain$CookBks=as.factor(CookBks)
>  cbcMain$DoItYBks=as.factor(DoItYBks)
>  cbcMain$RefBks=as.factor(RefBks)
>  cbcMain$ArtBks=as.factor(ArtBks)
>  cbcMain$GeogBks=as.factor(GeogBks)
>  cbcMain$ItalCook=as.factor(ItalCook)
>  cbcMain$ItalAtlas=as.factor(ItalAtlas)
>  cbcMain$ItalArt=as.factor(ItalArt)
>  cbcMain$Related.Purchase=as.factor(Related.Purchase)
Error in is.factor(x) : object 'Related.Purchase' not found
>  cbcMain$Florence=as.factor(Florence)
>  cbcMain$Gender=as.factor(Gender)
> cbcMain=cbind(cbcsubset,cbcsubset2)
> 
> attach(cbcMain)
The following object(s) are masked from 'cbcMain (position 4)':

    ArtBks, ChildBks, CookBks, DoItYBks, F, Florence, Gender, GeogBks, ItalArt, ItalAtlas, ItalCook, M, RefBks, YouthBks
The following object(s) are masked from 'cbcMain (position 5)':

    ArtBks, F, Florence, Gender, ItalArt, ItalAtlas, M
The following object(s) are masked from 'cbcMain (position 29)':

    ArtBks, ChildBks, CookBks, DoItYBks, F, Florence, Gender, GeogBks, ItalArt, ItalAtlas, ItalCook, M, RefBks, YouthBks
The following object(s) are masked from 'package:base':

    F
> cbcMain$M=as.factor(M)
>  cbcMain$R=as.factor(R)
>  cbcMain$F=as.factor(F)
>  cbcMain$FirstPurch=as.factor(FirstPurch)
>  cbcMain$ChildBks=as.factor(ChildBks)
>  cbcMain$YouthBks=as.factor(YouthBks)
>  cbcMain$CookBks=as.factor(CookBks)
>  cbcMain$DoItYBks=as.factor(DoItYBks)
>  cbcMain$RefBks=as.factor(RefBks)
>  cbcMain$ArtBks=as.factor(ArtBks)
>  cbcMain$GeogBks=as.factor(GeogBks)
>  cbcMain$ItalCook=as.factor(ItalCook)
>  cbcMain$ItalAtlas=as.factor(ItalAtlas)
>  cbcMain$ItalArt=as.factor(ItalArt)
>  cbcMain$Related.Purchase=as.factor(Related.Purchase)
>  cbcMain$Florence=as.factor(Florence)
>  cbcMain$Gender=as.factor(Gender)
>  summary(cbcMain)
 M        R        F        FirstPurch ChildBks YouthBks CookBks  DoItYBks RefBks   ArtBks   GeogBks  ItalCook ItalAtlas ItalArt  Related.Purchase Gender   Florence
 1:1004   1:1176   1:1227   1:1013     1:2424   1:3047   1:2338   1:2981   1:3181   1:3108   1:2933   1:3570   1:3870    1:3827   1:2095           0:1182   0:3662  
 2:1005   2: 998   2:1203   2: 994     3: 945   4: 953   3: 896   3: 722   4: 819   4: 892   3: 707   4: 430   4: 130    4: 173   3: 983           1:2818   1: 338  
 3: 995   3:1011   3: 624   3:1032     4: 631            4: 766   4: 297                     4: 360                               4: 922                            
 4: 996   4: 815   4: 946   4: 961                                                                                                                                  
> train=sample(1:4000,3000)
>  cbc_train=cbcMain[train,]
>  test=(1:4000)[-train]
>  cbc_test=cbcMain[test,]
> table(cbc_test$Florence)

  0   1 
913  87 
> modelnb = naiveBayes(Florence ~ ., data = cbc_train)
> table(cbc_train$Florence, predict(modelnb, cbc_train))
   
       0    1
  0 2604  145
  1  211   40
> pred=predict(modelnb, cbc_train)
> a=table(cbc_train$Florence, pred)
> e_nbtr=(a[1,2]+a[2,1])/(a[1,1]+a[2,2]+a[1,2]+a[2,1])*100
> e_nbtr
[1] 11.86667
> r_nbtr=(a[2,2])/(a[2,1]+a[2,2])*100
> r_nbtr
[1] 15.93625
> pred=predict(modelnb, cbc_test)
> a=table(cbc_test$Florence, pred)
> e_nbte=(a[1,2]+a[2,1])/(a[1,1]+a[2,2]+a[1,2]+a[2,1])*100
> r_nbte=(a[2,2])/(a[2,1]+a[2,2])*100
> r_nbte
[1] 10.34483
> names(cbcMain)
 [1] "M"                "R"                "F"                "FirstPurch"       "ChildBks"         "YouthBks"         "CookBks"          "DoItYBks"         "RefBks"          
[10] "ArtBks"           "GeogBks"          "ItalCook"         "ItalAtlas"        "ItalArt"          "Related.Purchase" "Gender"           "Florence"        
> cbcMains=cbcMain[,c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17)]
> cbcMains=SMOTE(Florence~.,cbcMains,prec.over=400)
> dim(cbcMains)
[1] 2366   17
> rownames(cbcMains)=as.character(seq(1:2366))
> table(cbcMains$Florence)

   0    1 
1352 1014 
> train=sample(1:2366,1800)
> cbcs_train=cbcMains[train,]
>  test=(1:2366)[-train]
> cbcs_test=cbcMains[test,]
> table(cbcs_train$Florence)

   0    1 
1038  762 
> table(cbcs_test$Florence)

  0   1 
314 252 
> modelnbs = naiveBayes(Florence ~ ., data = cbcs_train)
> table(cbcs_train$Florence, predict(modelnbs, cbcs_train))
   
      0   1
  0 776 262
  1 231 531
> a=table(cbcs_train$Florence, predict(modelnbs, cbcs_train))
> r_nbstr=(a[2,2])/(a[2,1]+a[2,2])*100
> r_nbstr
[1] 69.68504
> a=table(cbcs_test$Florence, predict(modelnbs, cbcs_test))
> r_nbste=(a[2,2])/(a[2,1]+a[2,2])*100
> r_nbste
[1] 65.47619
> table(cbc_test$Florence, predict(modelnbs, cbc_test))
   
      0   1
  0 666 247
  1  52  35
> a=table(cbc_test$Florence, predict(modelnbs, cbc_test))
> r_nbsote=(a[2,2])/(a[2,1]+a[2,2])*100
> r_nbsote
[1] 40.22989
> modeldtcart <- rpart(Florence ~ ., data = cbc_train, method="class", cp=0.001)
> printcp(modeldtcart)

Classification tree:
rpart(formula = Florence ~ ., data = cbc_train, method = "class", 
    cp = 0.001)

Variables actually used in tree construction:
[1] ArtBks           ChildBks         CookBks          FirstPurch       GeogBks          R                Related.Purchase

Root node error: 251/3000 = 0.083667

n= 3000 

         CP nsplit rel error xerror     xstd
1 0.0033201      0    1.0000 1.0000 0.060421
2 0.0010000      7    0.9761 1.0239 0.061072
>  prettyTree(modeldtcart)
> modeldtscart <- rpart(Florence ~ ., data = cbcs_train, method="class", cp=0.001)
> prettyTree(modeldtscart)
> printcp(modeldtscart)

Classification tree:
rpart(formula = Florence ~ ., data = cbcs_train, method = "class", 
    cp = 0.001)

Variables actually used in tree construction:
 [1] ArtBks           ChildBks         CookBks          DoItYBks        
 [5] F                FirstPurch       Gender           GeogBks         
 [9] ItalArt          ItalAtlas        ItalCook         M               
[13] R                RefBks           Related.Purchase YouthBks        

Root node error: 762/1800 = 0.42333

n= 1800 

          CP nsplit rel error  xerror     xstd
1  0.1994751      0   1.00000 1.00000 0.027510
2  0.0721785      1   0.80052 0.80052 0.026354
3  0.0446194      2   0.72835 0.72835 0.025712
4  0.0275591      3   0.68373 0.68373 0.025250
5  0.0183727      5   0.62861 0.65617 0.024938
6  0.0104987      6   0.61024 0.63386 0.024670
7  0.0052493     12   0.54724 0.63255 0.024654
8  0.0045932     13   0.54199 0.63517 0.024686
9  0.0039370     17   0.52362 0.62073 0.024506
10 0.0032808     21   0.50787 0.61942 0.024489
11 0.0026247     25   0.49475 0.62073 0.024506
12 0.0019685     26   0.49213 0.63648 0.024703
13 0.0017498     28   0.48819 0.65223 0.024892
14 0.0016404     31   0.48294 0.65223 0.024892
15 0.0013123     35   0.47638 0.65223 0.024892
16 0.0010000     50   0.45144 0.65617 0.024938
> fit2=prune(modeldtscart,cp=0.018)
> printcp(fit2)

Classification tree:
rpart(formula = Florence ~ ., data = cbcs_train, method = "class", 
    cp = 0.001)

Variables actually used in tree construction:
[1] ArtBks           GeogBks          ItalArt          Related.Purchase

Root node error: 762/1800 = 0.42333

n= 1800 

        CP nsplit rel error  xerror     xstd
1 0.199475      0   1.00000 1.00000 0.027510
2 0.072178      1   0.80052 0.80052 0.026354
3 0.044619      2   0.72835 0.72835 0.025712
4 0.027559      3   0.68373 0.68373 0.025250
5 0.018373      5   0.62861 0.65617 0.024938
6 0.018000      6   0.61024 0.63386 0.024670
> prettyTree(fit2)
> modeldtc45= J48(Florence ~ ., data = cbc_train)
> summary(modeldtc45)

=== Summary ===

Correctly Classified Instances        2749               91.6333 %
Incorrectly Classified Instances       251                8.3667 %
Kappa statistic                          0     
Mean absolute error                      0.1533
Root mean squared error                  0.2769
Relative absolute error                 99.8496 %
Root relative squared error             99.9999 %
Coverage of cases (0.95 level)         100      %
Mean rel. region size (0.95 level)     100      %
Total Number of Instances             3000     

=== Confusion Matrix ===

    a    b   <-- classified as
 2749    0 |    a = 0
  251    0 |    b = 1
> modeldtsc45= J48(Florence ~ ., data = cbcs_train)
> summary(modeldtsc45)

=== Summary ===

Correctly Classified Instances        1490               82.7778 %
Incorrectly Classified Instances       310               17.2222 %
Kappa statistic                          0.635 
Mean absolute error                      0.2662
Root mean squared error                  0.3648
Relative absolute error                 54.5255 %
Root relative squared error             73.8424 %
Coverage of cases (0.95 level)          99.8889 %
Mean rel. region size (0.95 level)      91.8056 %
Total Number of Instances             1800     

=== Confusion Matrix ===

   a   b   <-- classified as
 979  59 |   a = 0
 251 511 |   b = 1
> a=table(cbc_train$Florence, predict(modeldtc45,cbc_train))
> r_c45tr=(a[2,2])/(a[2,1]+a[2,2])*100
> r_c45tr
[1] 0
> a=table(cbcs_train$Florence, predict(modeldtsc45,cbcs_train))
> r_c45tr_cbcs=(a[2,2])/(a[2,1]+a[2,2])*100
> r_c45tr_cbcs
[1] 67.06037
> a=table(cbc_test$Florence, predict(modeldtc45,cbc_test))
> r_c45te=(a[2,2])/(a[2,1]+a[2,2])*100
> r_c45te
[1] 0
> a=table(cbcs_test$Florence, predict(modeldtsc45,cbcs_test))
> r_c45te_cbcs=(a[2,2])/(a[2,1]+a[2,2])*100
> r_c45te_cbcs
[1] 60.31746
> set.seed=1234
> modelrf=randomForest(Florence~., data=cbc_train, ntree=700)
> plot(modelrf)
> importance(modelrf)
                 MeanDecreaseGini
M                       30.572952
R                       30.456236
F                       19.594897
FirstPurch              17.873116
ChildBks                22.460329
YouthBks                11.796548
CookBks                 21.863307
DoItYBks                19.926422
RefBks                  11.836520
ArtBks                  11.266973
GeogBks                 17.817196
ItalCook                 8.645020
ItalAtlas                5.123720
ItalArt                  6.721516
Related.Purchase        12.792554
Gender                  12.776899
> modelrfs=randomForest(Florence~., data=cbcs_train, ntree=700)
> plot(modelrfs)
> importance(modelrfs)
                 MeanDecreaseGini
M                        62.77382
R                        67.12795
F                        74.10120
FirstPurch               64.92520
ChildBks                 45.81800
YouthBks                 22.85004
CookBks                  50.44143
DoItYBks                 39.63900
RefBks                   30.05395
ArtBks                   37.75557
GeogBks                  53.78339
ItalCook                 23.90670
ItalAtlas                14.03646
ItalArt                  41.76292
Related.Purchase         76.45490
Gender                   27.95630
>  a=table(cbc_train$Florence, predict(modelrf, cbc_train))
> r_rftr=(a[2,2])/(a[2,1]+a[2,2])*100
> r_rftr
[1] 39.44223
> a=table(cbcs_train$Florence, predict(modelrfs, cbcs_train))
> r_rftr_cbcs=(a[2,2])/(a[2,1]+a[2,2])*100
> r_rftr_cbcs
[1] 88.32021
> a=table(cbc_test$Florence, predict(modelrf,cbc_test))
> r_rfte=(a[2,2])/(a[2,1]+a[2,2])*100
>  r_rfte
[1] 2.298851
> a=table(cbcs_test$Florence, predict(modelrfs,cbcs_test))
>  r_rfte_cbcs=(a[2,2])/(a[2,1]+a[2,2])*100
>  r_rfte_cbcs
[1] 69.44444
>  modelab <- AdaBoostM1(Florence ~ .,cbc_train, control=Weka_control(I=100))
>  table(cbc_train$Florence, predict(modelab))
   
       0    1
  0 2749    0
  1  251    0
> modelabs <- AdaBoostM1(Florence ~ .,cbcs_train, control=Weka_control(I=100))
> table(cbcs_train$Florence, predict(modelabs))
   
      0   1
  0 877 161
  1 317 445
> a=table(cbc_train$Florence, predict(modelab, cbc_train))
> r_abtr=(a[2,2])/(a[2,1]+a[2,2])*100
>  r_abtr
[1] 0
> a=table(cbcs_train$Florence, predict(modelabs, cbcs_train))
> r_abtr_cbcs=(a[2,2])/(a[2,1]+a[2,2])*100
> r_abtr_cbcs
[1] 58.39895
> a=table(cbc_test$Florence, predict(modelab, cbc_test))
>  r_abte=(a[2,2])/(a[2,1]+a[2,2])*100
> r_abte
[1] 0
> a=table(cbcs_test$Florence, predict(modelabs, cbcs_test))
> r_abte_cbcs=(a[2,2])/(a[2,1]+a[2,2])*100
> r_abte_cbcs
[1] 57.53968
> recall_comp=matrix(c(r_nbtr, r_nbte, r_nbstr, r_nbste, r_c45tr, r_c45te,r_c45tr_cbcs,r_c45te_cbcs, r_rftr, r_rfte,r_rftr_cbcs,r_rfte_cbcs, r_abtr, r_abte,r_abtr_cbcs,r_abte_cbcs), nrow=1)
> colnames(recall_comp)=c('NB_Tr', 'NB_TE', 'NBS_TR', 'NBS_TE', 'C4.5TR', 'C4.5TE','C4.5TR_SMOTE','C4.5TE_SMOTE', 'RFTR', 'RFTE','RFTR_SMOTE','RFTE_SMOTE', 'ABTR', 'ABTE','ABTR_SMOTE','ABTE_SMOTE')
> recall_comp
        NB_Tr    NB_TE   NBS_TR   NBS_TE C4.5TR C4.5TE C4.5TR_SMOTE C4.5TE_SMOTE     RFTR     RFTE RFTR_SMOTE RFTE_SMOTE ABTR ABTE ABTR_SMOTE ABTE_SMOTE
[1,] 15.93625 10.34483 69.68504 65.47619      0      0     67.06037     60.31746 39.44223 2.298851   88.32021   69.44444    0    0   58.39895   57.53968
> 
